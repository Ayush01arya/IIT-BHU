{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d39d38c-1dc3-4a91-8dff-226a300117ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to 'word_data.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Input data\n",
    "data =  \n",
    "    \"ladZikA\", \"ladZikA\", \"ladZikana\", \"ladZikA\", \"ladZikana\",\n",
    "    \"rAjA\", \"rAjA\", \"rAjA\", \"rAjA\", \"rAjana\",\n",
    "    \"Gara\", \"Gara\", \"Gara\", \"Gara\", \"Garana\",\n",
    "    \"Karca\", \"Karca\", \"Karca\", \"Karca\", \"Karcana\",\n",
    "    \"kavi\", \"kavi\", \"kavi\", \"kavi\", \"kavina\",\n",
    "    \"AxamI\", \"AxamI\", \"AxamI\", \"AxamI\", \"Axamina\",\n",
    "    \"sawru\", \"sawru\", \"sawru\", \"sawru\", \"sawruna\",\n",
    "    \"AlU\", \"AlU\", \"AlU\", \"AlU\", \"Aluna\",\n",
    "    \"kuvAz\", \"kuvAz/kuAz/kuvAM/kuAM\", \"kuvAz/kuAz/kuvAM/kuAM\", \"kuvAz/kuAz/kuvAM/kuAM\", \"kuvazna/kuvaMna/kuazna/kuaMna\",\n",
    "    \"gehUz\", \"gehUz/gehUM\", \"gehUz/gehUM\", \"gehUz/gehUM\", \"gehuzna/gehuMna\",\n",
    "    \"kroXa\", \"kroXa\", \"kroXa\", \"kroXa\", \"kroXa\",\n",
    "    \"lakaTo\", \"lakaTo\", \"lakaTana/lakaTona\", \"lakaTo\", \"lakaTana/lakaTona\",\n",
    "    \"sarasoM\", \"sarasoM/sarasoz\", \"sarasoMna/sarasozna/sarasaMna/sarasazna\", \"sarasoM/sarasoz\", \"sarasoMna/sarasozna/sarasaMna/sarasazna\",\n",
    "    \"gosAIM\", \"gosAIM/gosAIz\", \"gosAIM/gosAIz\", \"gosAIM/gosAIz\", \"gosAIMana/gosAIzana\",\n",
    "    \"sonarA\", \"sonarA\", \"sonarA\", \"sonarA\", \"sonarana\"\n",
    " \n",
    "\n",
    "# Prepare the output structure\n",
    "categories =   \n",
    "word_roots =   \n",
    "word_forms =   \n",
    "\n",
    "# Process the input data\n",
    "for i in range(0, len(data), 5):\n",
    "    word_root = data i \n",
    "    word_form1 = data i + 1 \n",
    "    word_form2 = data i + 2 \n",
    "    word_form3 = data i + 3 \n",
    "    word_form4 = data i + 4 \n",
    "    \n",
    "    categories.append(\"Noun_m\")  # Assuming all are masculine nouns\n",
    "    word_roots.append(word_root)\n",
    "    word_forms.append( word_form1, word_form2, word_form3, word_form4 )\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Category': categories,\n",
    "    'Word Root': word_roots,\n",
    "    'Word Form 1':  forms 0  for forms in word_forms ,\n",
    "    'Word Form 2':  forms 1  for forms in word_forms ,\n",
    "    'Word Form 3':  forms 2  for forms in word_forms ,\n",
    "    'Word Form 4':  forms 3  for forms in word_forms ,\n",
    "})\n",
    "\n",
    "# Save to Excel\n",
    "df.to_excel('word_data1.xlsx', index=False)\n",
    "\n",
    "print(\"Data has been saved to 'word_data.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18f9d05c-7e6f-4cf6-959e-051f7ab251c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to 'word_data_new.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Input data (from noun_me_e.txt)\n",
    "data =  \n",
    "    \"ladZikA\", \"ladZike/ladZikai/ladZikE\", \"ladZikane/ladZikanai/ladZikanE\", \"ladZike/ladZikai/ladZikE\", \"ladZikane/ladZikanai/ladZikanE\",\n",
    "    \"rAjA\", \"rAje/rAjai/rAjE\", \"rAje/rAjai/rAjE\", \"rAje/rAjai/rAjE\", \"rAjanai/rAjane/rAjanE\",\n",
    "    \"Gara\", \"Gare/Garai/GarE\", \"Gare/Garai/GarE\", \"Gare/Garai/GarE\", \"Garanai/Garane/GaranE\",\n",
    "    \"Karca\", \"Karce/Karcai/KarcE\", \"Karce/Karcai/KarcE\", \"Karce/Karcai/KarcE\", \"Karcanai/Karcane/KarcanE\",\n",
    "    \"kavi\", \"kavie/kaviai/kaviE\", \"kavie/kaviai/kaviE\", \"kavie/kaviai/kaviE\", \"kavine/kavinai/kavinE\",\n",
    "    \"AxamI\", \"Axamie/Axamiai/AxamiE\", \"Axamie/Axamiai/AxamiE\", \"Axamie/Axamiai/AxamiE\", \"Axaminai/Axamine/AxaminE\",\n",
    "    \"sawru\", \"sawrue/sawruai/sawruE\", \"sawrue/sawruai/sawruE\", \"sawrue/sawruai/sawruE\", \"sawrune/sawrunai/sawrunE\",\n",
    "    \"AlU\", \"Alue/Aluai/AluE\", \"Alue/Aluai/AluE\", \"Alue/Aluai/AluE\", \"Alunai/Alune/AlunE\",\n",
    "    \"kuvAz\", \"kuveM/kuvEM/kuvaiM/kueM/kuvEM/kuvaiM/kuvez/kuvEz/kuvazi/kuez/kuEZ/kuaiz\", \n",
    "    \"kuveM/kuvEM/kuvaiM/kueM/kuvEM/kuvaiM/kuvez/kuvEz/kuvazi/kuez/kuEZ/kuaiz\", \n",
    "    \"kuveM/kuvEM/kuvaiM/kueM/kuvEM/kuvaiM/kuvez/kuvEz/kuvazi/kuez/kuEZ/kuaiz\", \n",
    "    \"kuvaznai/kuvaMnai/kuMvane/kuMvanE/kuzvane/kuzvanE/kuazne/kuaMne/kuaznai/kuaMnai/kuaznE/kuaMnE\",\n",
    "    \"gehUz\", \"gehUze/gehUMe/gehUzE/gehUME/gehUzai/gehUMai\", \"gehUze/gehUMe/gehUzE/gehUME/gehUzai/gehUMai\", \n",
    "    \"gehUze/gehUMe/gehUzE/gehUME/gehUzai/gehUMai\", \"gehuzne/gehuMne/gehuznai/gehuMnai/gehuznE/gehuMnE\",\n",
    "    \"kroXa\", \"kroXe/kroXE/kroXai\", \"kroXe/kroXE/kroXai\", \"kroXe/kroXE/kroXai\", \"kroXe/kroXE/kroXai\",\n",
    "    \"lakaTo\", \"lakaTe/lakaTai/lakaTE\", \"lakaTane/lakaTone/lakaTanai/lakaTonai/lakaTanE/lakaTonE\", \n",
    "    \"lakaTe/lakaTai/lakaTE\", \"lakaTane/lakaTone/lakaTanai/lakaTonai/lakaTanE/lakaTonE\",\n",
    "    \"sarasoM\", \"sarasoMeM/sarasozez/sarasoMEM/sarasozEz/sarasoMaiM/sarasozaiz\", \n",
    "    \"sarasoMne/sarasoznai/sarasaMnai/sarasaznai/sarasaMnE/sarasaznE\", \n",
    "    \"sarasoMeM/sarasozez/sarasoMEM/sarasozEz/sarasoMaiM/sarasozaiz\", \n",
    "    \"sarasoMne/sarasozne/sarasaMnai/sarasaznai/sarasaMnE/sarasaznE\",\n",
    "    \"gosAIM\", \"gosAIMe/gosAIze/gosAIMaiM/gosAIzaiz/gosAIMEM/gosAIzEz\", \n",
    "    \"gosAIMe/gosAIze/gosAIMaiM/gosAIzaiz/gosAIMEM/gosAIzEz\", \n",
    "    \"gosAIMe/gosAIze/gosAIMaiM/gosAIzaiz/gosAIMEM/gosAIzEz\", \n",
    "    \"gosAIManai/gosAIzanai/gosAIMane/gosAIzane/gosAIManE/gosAIzanE\",\n",
    "    \"sonarA\", \"sonare/sonarai/sonarE\", \"sonare/sonarai/sonarE\", \"sonare/sonarai/sonarE\", \"sonaranai/sonarane/sonaranE\"\n",
    " \n",
    "\n",
    "# Prepare the output structure\n",
    "categories =   \n",
    "word_roots =   \n",
    "word_forms =   \n",
    "\n",
    "# Process the input data\n",
    "for i in range(0, len(data), 5):\n",
    "    word_root = data i \n",
    "    word_form1 = data i + 1 \n",
    "    word_form2 = data i + 2 \n",
    "    word_form3 = data i + 3 \n",
    "    word_form4 = data i + 4 \n",
    "    \n",
    "    categories.append(\"Noun_m_e\")  # Based on the new file\n",
    "    word_roots.append(word_root)\n",
    "    word_forms.append( word_form1, word_form2, word_form3, word_form4 )\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Category': categories,\n",
    "    'Word Root': word_roots,\n",
    "    'Word Form 1':  forms 0  for forms in word_forms ,\n",
    "    'Word Form 2':  forms 1  for forms in word_forms ,\n",
    "    'Word Form 3':  forms 2  for forms in word_forms ,\n",
    "    'Word Form 4':  forms 3  for forms in word_forms ,\n",
    "})\n",
    "\n",
    "# Save to Excel\n",
    "df.to_excel('word_data_new.xlsx', index=False)\n",
    "\n",
    "print(\"Data has been saved to 'word_data_new.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bea91fa9-4e0a-4661-9937-9638363cd6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to 'word_data_noun_m_e1.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Input data\n",
    "data =  \n",
    "    \"ladZikA\", \"ladZiko/ladZikO/ladZikau\", \"ladZikano/ladZikanO/ladZikanau\", \"ladZiko/ladZikO/ladZikau\", \"ladZikanO/ladZikano/ladZikanau\",\n",
    "    \"rAjA\", \"rAjo/rAjO/rAjau\", \"rAjo/rAjO/rAjau\", \"rAjo/rAjO/rAjau\", \"rAjano/rAjanO/rAjanau\",\n",
    "    \"Gara\", \"Garo/GarO/Garau\", \"Garo/GarO/Garau\", \"Garo/GarO/Garau\", \"Garano/GaranO/Garanau\",\n",
    "    \"Karca\", \"Karco/KarcO/Karcau\", \"Karco/KarcO/Karcau\", \"Karco/KarcO/Karcau\", \"Karcano/KarcanO/Karcanau\",\n",
    "    \"kavi\", \"kavio/kaviau/kaviO\", \"kavio/kaviau/kaviO\", \"kavio/kaviau/kaviO\", \"kavino/kavinau/kavinO\",\n",
    "    \"AxamI\", \"Axamio/Axamiau/AxamiO\", \"Axamio/Axamiau/AxamiO\", \"Axamio/Axamiau/AxamiO\", \"Axaminau/Axamino/AxaminO\",\n",
    "    \"sawru\", \"sawruo/sawruau/sawruO\", \"sawruo/sawruau/sawruO\", \"sawruo/sawruau/sawruO\", \"sawruno/sawrunau/sawrunO\",\n",
    "    \"AlU\", \"Aluo/Aluau/AluO\", \"Aluo/Aluau/AluO\", \"Aluo/Aluau/AluO\", \"Alunau/Aluno/AlunO\",\n",
    "    \"kuvAz\", \"kuvoM/kuvOM/kuvauM/kuvoz/kuvOz/kuvauz/kuoM/kuOM/kuaMu/kuoz/kuOz/kuazu\", \"kuvoM/kuvOM/kuvauM/kuvoz/kuvOz/kuvauz/kuoM/kuOM/kuaMu/kuoz/kuOz/kuazu\", \n",
    "    \"kuvoM/kuvOM/kuvauM/kuvoz/kuvOz/kuvauz/kuoM/kuOM/kuaMu/kuoz/kuOz/kuazu\", \"kuvaznau/kuvaMnau/kuMvano/kuMvanO/kuzvano/kuzvanO/kuazno/kuaMno/kuaznau/kuaMnau/kuaznO/kuaMnO\",\n",
    "    \"gehUz\", \"gehUzo/gehUMo/gehUzO/gehUMO/gehUzau/gehUMau\", \"gehUzo/gehUMo/gehUzO/gehUMO/gehUzau/gehUMau\", \"gehUzo/gehUMo/gehUzO/gehUMO/gehUzau/gehUMau\", \n",
    "    \"gehuzno/gehuMno/gehuznau/gehuMnau/gehuznO/gehuMnO\", \n",
    "    \"kroXa\", \"kroXo/kroXO/kroXau\", \"kroXo/kroXO/kroXau\", \"kroXo/kroXO/kroXau\", \"kroXo/kroXO/kroXau\",\n",
    "    \"lakaTo\", \"lakaTo/lakaTau/lakaTO\", \"lakaTano/lakaTono/lakaTanau/lakaTonau/lakaTanO/lakaTonO\", \"lakaTo/lakaTau/lakaTO\", \n",
    "    \"lakaTano/lakaTono/lakaTanau/lakaTonau/lakaTanO/lakaTonO\",\n",
    "    \"sarasoM\", \"sarasoMoM/sarasozoz/sarasoMOM/sarasozOz/sarasoMauM/sarasozauz\", \"sarasoMno/sarasoznau/sarasaMnau/sarasaznau/sarasaMnO/sarasaznO\", \n",
    "    \"sarasoMoM/sarasozoz/sarasoMOM/sarasozOz/sarasoMauM/sarasozauz\", \"sarasoMno/sarasozno/sarasaMnau/sarasaznau/sarasaMnO/sarasaznO\",\n",
    "    \"gosAIM\", \"gosAIMo/gosAIzo/gosAIMauM/gosAIzauz/gosAIMOM/gosAIzOz\", \"gosAIMo/gosAIzo/gosAIMauM/gosAIzauz/gosAIMOM/gosAIzOz\", \n",
    "    \"gosAIMo/gosAIzo/gosAIMauM/gosAIzauz/gosAIMOM/gosAIzOz\", \"gosAIManau/gosAIzanau/gosAIMano/gosAIzano/gosAIManO/gosAIzanO\",\n",
    "    \"sonarA\", \"sonaro/sonarau/sonarO\", \"sonaro/sonarau/sonarO\", \"sonaro/sonarau/sonarO\", \"sonaranau/sonarano/sonaranO\"\n",
    " \n",
    "\n",
    "# Prepare the output structure\n",
    "categories =   \n",
    "word_roots =   \n",
    "word_forms =   \n",
    "\n",
    "# Process the input data\n",
    "for i in range(0, len(data), 5):\n",
    "    word_root = data i \n",
    "    word_form1 = data i + 1 \n",
    "    word_form2 = data i + 2 \n",
    "    word_form3 = data i + 3 \n",
    "    word_form4 = data i + 4 \n",
    "    \n",
    "    categories.append(\"Noun_m_e1\")  # New category for this dataset\n",
    "    word_roots.append(word_root)\n",
    "    word_forms.append( word_form1, word_form2, word_form3, word_form4 )\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Category': categories,\n",
    "    'Word Root': word_roots,\n",
    "    'Word Form 1':  forms 0  for forms in word_forms ,\n",
    "    'Word Form 2':  forms 1  for forms in word_forms ,\n",
    "    'Word Form 3':  forms 2  for forms in word_forms ,\n",
    "    'Word Form 4':  forms 3  for forms in word_forms ,\n",
    "})\n",
    "\n",
    "# Save to Excel\n",
    "df.to_excel('word_data_noun_m_e1.xlsx', index=False)\n",
    "\n",
    "print(\"Data has been saved to 'word_data_noun_m_e1.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7caf8507-396f-4820-a594-654d88172072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to 'word_data_noun_m_e1.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Input data\n",
    "data =  \n",
    "    \"ladZakI\", \"ladZakI\", \"ladZakina\", \"ladZakI\", \"ladZakina\",\n",
    "    \"mAI\", \"mAI/mAyI\", \"mAina/mAyana\", \"mAI/mAyI\", \"mAina/mAyana\",\n",
    "    \"rAwa\", \"rAwa\", \"rAwa\", \"rAwa\", \"rAwana\",\n",
    "    \"rAwi\", \"rAwi\", \"rAwi\", \"rAwi\", \"rAwina\",\n",
    "    \"Orawa\", \"Orawa\", \"Orawana\", \"Orawa\", \"Orawana\",\n",
    "    \"BAsA\", \"BAsA\", \"BAsA\", \"BAsA\", \"BAsana\",\n",
    "    \"gudZiyA\", \"gudZiyA/gudZiA\", \"gudZiyA/gudZiA\", \"gudZiyA/gudZiA\", \"gudZiyana/gudZiana\",\n",
    "    \"sakwi\", \"sakwi\", \"sakwi\", \"sakwi\", \"sakwina\",\n",
    "    \"qwu\", \"qwu\", \"qwu\", \"qwu\", \"qwuna\",\n",
    "    \"bahU\", \"bahU\", \"bahuna\", \"bahU\", \"bahuna\",\n",
    "    \"lO\", \"lO\", \"lOana\", \"lO\", \"lOana\",\n",
    "    \"mAz\", \"mAz/mAM\", \"mAzvana/mAzyana/mAzina/mAMvana/mAMyana/mAMzina\", \"mAz/mAM\", \"mAzvana/mAzyana/mAzina/mAMvana/mAMyana/mAMzina\",\n",
    "    \"Poto\", \"Poto\", \"Poto\", \"Poto\", \"Potona\",\n",
    "    \"PotoM\", \"PotoM/Potoz\", \"PotoM/Potoz\", \"PotoM/Potoz\", \"PotoMna/Potozna\",\n",
    "    \"BUiM\", \"BUiM/BUiz/BUIM/BUIz\", \"BUiMana/BUizana/BUIMna/BUIzna\", \"BUiM/BUiz/BUIM/BUIz\", \"BUiMana/BUizana/BUIMna/BUIzna\",\n",
    "    \"BOM\", \"BOM/BOz\", \"BOMana/BOzana/Bazuana/BaMuana\", \"BOM/BOz\", \"BOMana/BOzana/Bazuana/BaMuana\",\n",
    "    \"BarasAIM\", \"BarasAIM/BarasAIz\", \"BarasAiMna/barasAizna\", \"BarasAIM/BarasAIz\", \"BarasAiMna/barasAizna\",\n",
    "    \"Bora\", \"Bora\", \"Bora\", \"Bora\", \"Borana\"\n",
    " \n",
    "\n",
    "# Prepare the output structure\n",
    "categories =   \n",
    "word_roots =   \n",
    "word_forms =   \n",
    "\n",
    "# Process the input data\n",
    "for i in range(0, len(data), 5):\n",
    "    word_root = data i \n",
    "    word_form1 = data i + 1 \n",
    "    word_form2 = data i + 2 \n",
    "    word_form3 = data i + 3 \n",
    "    word_form4 = data i + 4 \n",
    "    \n",
    "    categories.append(\"Noun_m_e1\")  # New category for this dataset\n",
    "    word_roots.append(word_root)\n",
    "    word_forms.append( word_form1, word_form2, word_form3, word_form4 )\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Category': categories,\n",
    "    'Word Root': word_roots,\n",
    "    'Word Form 1':  forms 0  for forms in word_forms ,\n",
    "    'Word Form 2':  forms 1  for forms in word_forms ,\n",
    "    'Word Form 3':  forms 2  for forms in word_forms ,\n",
    "    'Word Form 4':  forms 3  for forms in word_forms ,\n",
    "})\n",
    "\n",
    "# Save to Excel\n",
    "df.to_excel('word_data_noun_f.xlsx', index=False)\n",
    "\n",
    "print(\"Data has been saved to 'word_data_noun_m_e1.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e10f063-5542-481c-9fe4-b6b37844b0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to 'word_data_noun_f_e.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Input data\n",
    "data = [\n",
    "    'ladZakI', 'ladZakie', 'ladZakiai', 'ladZakiE', 'ladZakine', 'ladZakinai', 'ladZakinE',\n",
    "    'mAI', 'mAie', 'maie', 'maiai', 'maiE', 'mAiE', 'mAiai', 'mAyie', 'mAyiai', 'mAyE', 'mAine', 'mAinai', 'mAinE',\n",
    "    'rAwa', 'rAwe', 'rAwai', 'rAwE', 'rAwane', 'rAwanai', 'rAwanE',\n",
    "    'rAwi', 'rAwie', 'rAwie', 'rAwiai', 'rAwine', 'rAwinai', 'rawine',\n",
    "    'Orawa', 'Orawe', 'Orawai', 'OrawE', 'Orawane', 'Orawanai', 'OrawanE',\n",
    "    'BAsA', 'BAse', 'BAsai', 'BAsE', 'BAsane', 'BAsanai', 'BAsanE',\n",
    "    'gudZiyA', 'gudZiye', 'gudZie', 'gudZiyai', 'gudZiai', 'gudZiE', 'gudZiyE', 'gudZiyanai', 'gudZiyane', 'gudZianai', 'gudZiane', 'gudZiyanE', 'gudZianE',\n",
    "    'sakwi', 'sakwie', 'sakwiai', 'sakwiE', 'sakwine', 'sakwinai', 'sakwinaE',\n",
    "    'qwu', 'qwue', 'qwuai', 'qwuE', 'qwune', 'qwuanai', 'qwunE',\n",
    "    'bahU', 'bahue', 'bahuai', 'bahuE', 'bahune', 'bahunai', 'bahunE',\n",
    "    'lO', 'lOe', 'lOai', 'lOE', 'lOne', 'lOnai', 'lOnE',\n",
    "    'mAz', 'mAzai', 'mAzE', 'mAze', 'mAMai', 'mAME', 'mAMe', 'mAzvanai', 'mAzvanE', 'mAzvane', 'mAMvanai', 'mAMvanE', 'mAMvane', 'mAzyanai', 'mAzyanE', 'mAzyane', 'mAMyanai', 'mAMyanE', 'mAMyane', 'mAzine', 'mAzinai', 'mAzinE', 'mAMzine', 'mAMzinai', 'mAMzinE',\n",
    "    'Poto', 'Potoe', 'Potoai', 'PotoE', 'Potone', 'Potonai', 'PotonE',\n",
    "    'PotoM', 'Potoze', 'Potazai', 'PotozE', 'PotoMe', 'PotoMai', 'PotoME', 'Potozne', 'Potoznai', 'PotoznE', 'PotoMne', 'PotoMnai', 'PotoMnE',\n",
    "    'BUiM', 'BUiMe', 'BUize', 'BUiMai', 'BUizai', 'BUiME', 'BUizE', 'BUiMane', 'BUizane', 'BUiManai', 'BUizanai', 'BUiManE', 'BUizanE',\n",
    "    'BOM', 'BOMe', 'BOze', 'BOzue', 'BOMue', 'BOME', 'BOzE', 'BOzuE', 'BOMuE', 'BOMai', 'BOzai', 'BOzuai', 'BOMuai', 'BOMane', 'BOzane', 'Bazuane', 'BaMuane', 'BOManai', 'BOzanai', 'Bazuanai', 'BaMuanai', 'BOManE', 'BOzanE', 'BazuanE', 'BaMuanE',\n",
    "    'BarasAIM', 'BarasAiMeM', 'BarasAizez', 'BarasaiMaiM', 'Barasaizaiz', 'BarasAiMEM', 'BarasAizEz', 'BarasAiMne', 'BarasAizne', 'BarasAiMnaiM', 'BarasAiznaiz', 'BarasaiMne', 'Barasaizne', 'BarasaiMnaiM', 'Barasaiznaiz',\n",
    "    'Bora', 'Bore', 'Borai', 'BorE', 'Borane', 'Boranai', 'BoranE'\n",
    "]\n",
    "\n",
    "# Prepare the output structure\n",
    "categories = []\n",
    "word_roots = []\n",
    "word_forms = []\n",
    "\n",
    "# Process the input data\n",
    "for i in range(0, len(data), 7):\n",
    "    word_root = data[i]\n",
    "    forms = data[i+1:i+7]\n",
    "    \n",
    "    categories.append(\"Noun_f_e\")  # New category for this dataset\n",
    "    word_roots.append(word_root)\n",
    "    word_forms.append(forms + [''] * (4 - len(forms)))  # Pad with empty strings to ensure 4 columns\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Category': categories,\n",
    "    'Word Root': word_roots,\n",
    "    'Word Form 1': [forms[0] for forms in word_forms],\n",
    "    'Word Form 2': [forms[1] for forms in word_forms],\n",
    "    'Word Form 3': [forms[2] for forms in word_forms],\n",
    "    'Word Form 4': [forms[3] for forms in word_forms],\n",
    "})\n",
    "\n",
    "# Save to Excel\n",
    "df.to_excel('word_data_noun_f_e.xlsx', index=False)\n",
    "\n",
    "print(\"Data has been saved to 'word_data_noun_f_e.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b7ee1fc-293c-4955-8393-7683d479e2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to 'word_data_noun_f_e1.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Input data\n",
    "data = [\n",
    "    ('ladZakI', 'ladZakio/ladZakiau/ladZakiO', 'ladZakino/ladZakinau/ladZakinO', 'ladZakio/ladZakiau/ladZakiO', 'ladZakino/ladZakinau/ladZakinO'),\n",
    "    ('mAI', 'mAio/mAiau/mAiO/maio/maiau/maiO/mAyio/mAyiau/mAyiO', 'mAino/mAinau/mAinO/maino/mainau/mainO/mAyano/mAyanau/mAyanO', 'mAio/mAiau/mAiO/maio/maiau/maiO/mAyio/mAyiau/mAyiO', 'mAino/mAinau/mAinO/maino/mainau/mainO/mAyano/mAyanau/mAyanO'),\n",
    "    ('rAwa', 'rAwo/rAwO/rAwau', 'rAwo/rAwO/rAwau', 'rAwo/rAwO/rAwau', 'rAwano/rAwanO/rAwanau'),\n",
    "    ('rAwi', 'rAwio/rAwiau/rAwiO', 'rAwio/rAwiau/rAwiO', 'rAwio/rAwiau/rAwiO', 'rAwino/rAwinau/rawinO'),\n",
    "    ('Orawa', 'Orawo/Orawau/OrawO', 'Orawano/Orawanau/OrawanaO/Orawino', 'Orawo/Orawau/OrawO', 'Orawano/Orawanau/OrawanaO/Orawino'),\n",
    "    ('BAsA', 'BAso/BAsO/BAsau/Baso/Basau/BasO', 'BAso/BAsO/BAsau/Baso/Basau/BasO', 'BAso/BAsO/BAsau/Baso/Basau/BasO', 'BAsano/BAsanO/BAsanau/Basano/Basanau/BasanO'),\n",
    "    ('gudZiyA', 'gudZiyo/gudZiyO/gudZiyau/gudZio/gudZiau/gudZiO', 'gudZiyo/gudZiyO/gudZiyau/gudZio/gudZiau/gudZiO', 'gudZiyo/gudZiyO/gudZiyau/gudZio/gudZiau/gudZiO', 'gudZiyano/gudZiyanO/gudZiyanau/gudZiano/gudZianO/gudZianau'),\n",
    "    ('sakwi', 'sakwio/sakwiau/sakwiO', 'sakwio/sakwiau/sakwiO', 'sakwio/sakwiau/sakwiO', 'sakwino/sakwinau/sakwinaO'),\n",
    "    ('qwu', 'qwuo/qwuau/qwuO', 'qwuo/qwuau/qwuO', 'qwuo/qwuau/qwuO', 'qwuno/qwuanau/qwunO'),\n",
    "    ('bahU', 'bahuo/bahuau/bahuO', 'bahuno/bahunau/bahunO', 'bahuo/bahuau/bahuO', 'bahuno/bahunau/bahunO'),\n",
    "    ('lO', 'lOVo/lOVO/lOau', 'lOno/lOnO/lOnau', 'lOVo/lOVO/lOau', 'lOno/lOnO/lOnau'),\n",
    "    ('mAz', 'mAzau/mAzO/mAzo/mAMau/mAMO/mAMo', 'mAzvanau/mAzvanO/mAzvano/mAMvanau/mAMvanO/mAMvano/mAzyanau/mAzyanO/mAzyano/mAMyanau/mAMyanO/mAMyano/mAzino/mAzinau/mAzinO/mAMzino/mAMzinau/mAMzinO', 'mAzau/mAzO/mAzo/mAMau/mAMO/mAMo', 'mAzvanau/mAzvanO/mAzvano/mAMvanau/mAMvanO/mAMvano/mAzyanau/mAzyanO/mAzyano/mAMyanau/mAMyanO/mAMyano/mAzino/mAzinau/mAzinO/mAMzino/mAMzinau/mAMzinO'),\n",
    "    ('Poto', 'Potoo/Potoau/PotoO', 'Potoo/Potoau/PotoO', 'Potoo/Potoau/PotoO', 'Potono/Potanau/PotanO'),\n",
    "    ('PotoM', 'PotoMo/Potozo/PotoMau/Potazau/PotoMO/PotozO', 'PotoMo/Potozo/PotoMau/Potazau/PotoMO/PotozO', 'PotoMo/Potozo/PotoMau/Potazau/PotoMO/PotozO', 'PotoMno/Potozno/Potoznau/PotoMnau/PotoMnO/PotoznO'),\n",
    "    ('BUiM', 'BUiMo/BUizo/BUiMau/BUizau/BUiMO/BUizO', 'BUiMano/BUizano/BUiManau/BUizanau/BUiManO/BUizanO', 'BUiMo/BUizo/BUiMau/BUizau/BUiMO/BUizO', 'BUiMano/BUizano/BUiManau/BUizanau/BUiManO/BUizanO'),\n",
    "    ('BOM', 'BOMo/BOzo/BOzuo/BOMuo/BOMO/BOzO/BOzuO/BOMuO/BOMau/BOzau/BOzuau/BOMuau', 'BOMano/BOzano/Bazuano/BaMuano/BOManau/BOzanau/Bazuanau/BaMuanau/BOManO/BOzanO/BazuanO/BaMuanO', 'BOMo/BOzo/BOzuo/BOMuo/BOMO/BOzO/BOzuO/BOMuO/BOMau/BOzau/BOzuau/BOMuau', 'BOMano/BOzano/Bazuano/BaMuano/BOManau/BOzanau/Bazuanau/BaMuanau/BOManO/BOzanO/BazuanO/BaMuanO'),\n",
    "    ('BarasAIM', 'BarasAiMoM/BarasAizoz/BarasaiMauM/Barasaizauz/BarasAiMOM/BarasAizOz', 'BarasAiMno/BarasAizno/BarasAiMnauM/BarasAiznauz/BarasaiMno/Barasaizno/BarasaiMnauM/Barasaiznauz', 'BarasAiMoM/BarasAizoz/BarasaiMauM/Barasaizauz/BarasAiMOM/BarasAizOz', 'BarasAiMno/BarasAizno/BarasAiMnauM/BarasAiznauz/BarasaiMno/Barasaizno/BarasaiMnauM/Barasaiznauz'),\n",
    "    ('Bora', 'Boro/BorO/Borau', 'Boro/BorO/Borau', 'Boro/BorO/Borau', 'Borano/BoranO/Boranau')\n",
    "]\n",
    "\n",
    "# Prepare the output structure\n",
    "categories = []\n",
    "word_roots = []\n",
    "word_forms = []\n",
    "\n",
    "# Process the input data\n",
    "for entry in data:\n",
    "    word_root, form1, form2, form3, form4 = entry\n",
    "    categories.append(\"Noun_f_e1\")  # New category for this dataset\n",
    "    word_roots.append(word_root)\n",
    "    word_forms.append([form1, form2, form3, form4])\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Category': categories,\n",
    "    'Word Root': word_roots,\n",
    "    'Word Form 1': [forms[0] for forms in word_forms],\n",
    "    'Word Form 2': [forms[1] for forms in word_forms],\n",
    "    'Word Form 3': [forms[2] for forms in word_forms],\n",
    "    'Word Form 4': [forms[3] for forms in word_forms],\n",
    "})\n",
    "\n",
    "# Save to Excel\n",
    "df.to_excel('word_data_noun_f_e1.xlsx', index=False)\n",
    "\n",
    "print(\"Data has been saved to 'word_data_noun_f_e1.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcbaca63-ec2c-43a8-b81d-fca49816deee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to 'word_data_noun_f_rednt.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Input data\n",
    "data = [\n",
    "    ('ladZakiyA', 'ladZakiyA', 'ladZakiyana/ladZakiana', 'ladZakiyA', 'ladZakiyana/ladZakiana'),\n",
    "    ('maiyA', 'maiyA/maiA', 'maiyana/maiana', 'maiyA/maiA', 'maiyana/maiana'),\n",
    "    ('rawiyA', 'rawiyA/rawiA', 'rawiyA/rawiA', 'rawiyA/rawiA', 'rawiyana/rawiana'),\n",
    "    ('OrawiyA', 'OrawiyA/OrawiA', 'Orawiyana/Orawiana', 'OrawiyA/OrawiA', 'Orawiyana/Orawiana'),\n",
    "    ('BasavA', 'BasavA', 'BasavA', 'BasavA', 'Basavana'),\n",
    "    ('lauvA', 'lauvA/lauA', 'lauvana/lauana', 'lauvA/lauA', 'lauvana/lauana'),\n",
    "    ('gudZiyavA', 'gudZiyavA/gudZiavA', 'gudZiyavA/gudZiavA', 'gudZiyavA/gudZiavA', 'gudZiyavana/gudZiavana'),\n",
    "    ('sakwiyA', 'sakwiyA/sakwiA', 'sakwiyA/sakwiA', 'sakwiyA/sakwiA', 'sakwiyana/sakwiana'),\n",
    "    ('qwuvA', 'qwuvA/qwuA', 'qwuvA/qwuA', 'qwuvA/qwuA', 'qwuvana/qwuana'),\n",
    "    ('bahuvA', 'bahuvA/bahuA', 'bahuvana/bahuana', 'bahuvA/bahuA', 'bahuvana/bahuana'),\n",
    "    ('BoravA', 'BoravA', 'BoravA', 'BoravA', 'Boravana'),\n",
    "    ('BarasaiMyAM', 'BarasaiMyAM/BarasaiMyAz', 'BarasaiMyana/Barasaizyana', 'BarasaiMyAM/BarasaiMyAz', 'BarasaiMyana/Barasaizyana/BarasaiMana/Barasaizana'),\n",
    "    ('BOMvAM', 'BOMvAM/BOzvAz', 'BOMvana/BOzvana', 'BOMvAM/BOzvAz', 'BOMvana/BOzvana'),\n",
    "    ('PotoMiyAM', 'PotoMiyAM/PotoMiyAz', 'PotoMiyAM/PotoMiyAz', 'PotoMiyAM/PotoMiyAz', 'PotoMiyana/Potoziyana/PotoMiana/Potoziana'),\n",
    "    ('BuiMyAM', 'BuiMyAM/BuiMyAz/BuizyAM/BuizyAz', 'BuiMyana/Buizyana/BuiMana/Buizana', 'BuiMyAM/BuiMyAz/BuizyAM/BuizyAz', 'BuiMyana/Buizyana/BuiMana/Buizana'),\n",
    "    ('PotoiyA', 'PotoiyA', 'PotoiyA', 'PotoiyA', 'Potoiyana/Potoiana')\n",
    "]\n",
    "\n",
    "# Prepare the output structure\n",
    "categories = []\n",
    "word_roots = []\n",
    "word_forms = []\n",
    "\n",
    "# Process the input data\n",
    "for entry in data:\n",
    "    word_root, form1, form2, form3, form4 = entry\n",
    "    categories.append(\"Noun_f_rednt\")  # New category for this dataset\n",
    "    word_roots.append(word_root)\n",
    "    word_forms.append([form1, form2, form3, form4])\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Category': categories,\n",
    "    'Word Root': word_roots,\n",
    "    'Word Form 1': [forms[0] for forms in word_forms],\n",
    "    'Word Form 2': [forms[1] for forms in word_forms],\n",
    "    'Word Form 3': [forms[2] for forms in word_forms],\n",
    "    'Word Form 4': [forms[3] for forms in word_forms],\n",
    "})\n",
    "\n",
    "# Save to Excel\n",
    "df.to_excel('word_data_noun_f_rednt.xlsx', index=False)\n",
    "\n",
    "print(\"Data has been saved to 'word_data_noun_f_rednt.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3166acfe-7a7f-45bb-9d27-f551fd136cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to 'word_data_noun_f_rednt_e.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Input data\n",
    "data = [\n",
    "    ('ladZakiyA', 'ladZakiye/ladZakiyai/ladZakiyE', 'ladZakiyanai/ladZakiyane/ladZakiyanE/ladZakianai/ladZakiane/ladZakianE', 'ladZakiye/ladZakiyai/ladZakiyE', 'ladZakiyanai/ladZakiyane/ladZakiyanE/ladZakianai/ladZakiane/ladZakianE'),\n",
    "    ('maiyA', 'maiye/maiyai/maiyE/maie/maiai/maiE', 'maiyanai/maiyane/maiyanE/maianai/maiane/maianE', 'maiye/maiyai/maiyE/maie/maiai/maiE', 'maiyanai/maiyane/maiyanE/maianai/maiane/maianE'),\n",
    "    ('rawiyA', 'rawiye/rawiyai/rawiyE/rawie/rawiai/rawiE', 'rawiye/rawiyai/rawiyE/rawie/rawiai/rawiE', 'rawiye/rawiyai/rawiyE/rawie/rawiai/rawiE', 'rawiyanai/rawiyane/rawiyanE/rawiane/rawianai/rawianE'),\n",
    "    ('OrawiyA', 'Orawiye/Orawiyai/OrawiyE/Orawie/Orawiai/OrawiE', 'Orawiyanai/Orawiyane/OrawiyanE/Orawiane/Orawianai/OrawianE', 'Orawiye/Orawiyai/OrawiyE/Orawie/Orawiai/OrawiE', 'Orawiyanai/Orawiyane/OrawiyanE/Orawiane/Orawianai/OrawianE'),\n",
    "    ('BasavA', 'Basave/Basavai/BasavE', 'Basave/Basavai/BasavE', 'Basave/Basavai/BasavE', 'Basavanai/Basavane/BasavanE'),\n",
    "    ('lauvA', 'lauve/lauvai/lauvE/laue/lauai/lauE', 'lauvane/lauvanE/lauvanai/lauane/lauanai/laquanE', 'lauve/lauvai/lauvE/laue/lauai/lauE', 'lauvane/lauvanE/lauvanai/lauane/lauanai/laquanE'),\n",
    "    ('gudZiyavA', 'gudZiyavai/gudZiyave/gudZiyavE/gudZiavai/gudZiave/gudZiavE', 'gudZiyavai/gudZiyave/gudZiyavE/gudZiavai/gudZiave/gudZiavE', 'gudZiyavai/gudZiyave/gudZiyavE/gudZiavai/gudZiave/gudZiavE', 'gudZiyavanai/gudZiyavane/gudZiyavanE/gudZiavane/gudZiavanai/gudZiavanE'),\n",
    "    ('sakwiyA', 'sakwiye/sakwiyai/sakwiyE', 'sakwiye/sakwiyai/sakwiyE', 'sakwiye/sakwiyai/sakwiyE', 'sakwiyanai/sakwiyane/sakwiyanE'),\n",
    "    ('bahuvA', 'bahuve/bahuvai/bahuvE', 'bahuve/bahuvai/bahuvE', 'bahuve/bahuvai/bahuvE', 'bahuvanai/bahuvane/bahuvanE'),\n",
    "    ('qwuvA', 'qwuve/qwuvE/qwuvai', 'qwuve/qwuvE/qwuvai', 'qwuve/qwuvE/qwuvai', 'qwuvane/qwuvanE/qwuvnai'),\n",
    "    ('BoravA', 'Borave/Boravai/BoravE', 'Borave/Boravai/BoravE', 'Borave/Boravai/BoravE', 'Boravanai/Boravane/BoravanE'),\n",
    "    ('BarasaiMyAM', 'BarasaiMyeM/BarasaiMyEM/BarasaiMyaiM/BarasaiMyez/BarasaiMyEz/BarasaiMyaiz/BarasaizyeM/BarasaizyEM/BarasaizyaiM/Barasaizyez/BarasaizyEz/Barasaizyaiz', 'BarasaiMyaneM/BarasaiMyanaiM/BarasaiMyanEM/BarasaiMyanez/BarasaiMyanaiz/BarasaiMyanEz/Barasaizyanez/Barasaizyanaiz/BarasaizyanEz/BarasaizyaneM/BarasaizyanaiM/BarasaizyanEM', 'BarasaiMyeM/BarasaiMyEM/BarasaiMyaiM/BarasaiMyez/BarasaiMyEz/BarasaiMyaiz/BarasaizyeM/BarasaizyEM/BarasaizyaiM/Barasaizyez/BarasaizyEz/Barasaizyaiz', 'BarasaiMyaneM/BarasaiMyanaiM/BarasaiMyanEM/BarasaiMyanez/BarasaiMyanaiz/BarasaiMyanEz/Barasaizyanez/Barasaizyanaiz/BarasaizyanEz/BarasaizyaneM/BarasaizyanaiM/BarasaizyanEM'),\n",
    "    ('BOMvAM', 'BOMveM/BOzvez/BOMvaiM/BOzvaiz/BOMvEM/BOzvEz/BOMvez/BOzveM/BOMvaiz/BOzvaiM/BOMvEz/BOzvEM', 'BOMvane/BOMvanai/BOMvanai/Bozvane/Bozvanai/BozvanE', 'BOMveM/BOzvez/BOMvaiM/BOzvaiz/BOMvEM/BOzvEz/BOMvez/BOzveM/BOMvaiz/BOzvaiM/BOMvEz/BOzvEM', 'BOMvane/Bozvane/BOMvanai/BOzvanai/BOMvanE/BozvanEe/'),\n",
    "    ('PotoM', 'PotoMiyeM/Potoziyez/PotoMiyez/PotoziyeM/PotoMiyEM/PotoziyEz/PotoMiyEz/PotoziyEM/PotoMiyaiM/Potoziyaiz/PotoMiyaiz/PotoziyaiM', 'PotoMiyeM/Potoziyez/PotoMiyez/PotoziyeM/PotoMiyEM/PotoziyEz/PotoMiyEz/PotoziyEM/PotoMiyaiM/Potoziyaiz/PotoMiyaiz/PotoziyaiM', 'PotoMiyeM/Potoziyez/PotoMiyez/PotoziyeM/PotoMiyEM/PotoziyEz/PotoMiyEz/PotoziyEM/PotoMiyaiM/Potoziyaiz/PotoMiyaiz/PotoziyaiM', 'PotoMiyane/Potoziyane/PotoMiyanai/Potoziyanai/PotoMiyanE/PotoziyanE'),\n",
    "    ('BuiMyAM', 'BuiMyeM/Buizyez/BuiMyez/BuizyeM/BuiMyaiM/Buizyaiz/BuiMyaiz/BuizyaiM/BuiMyEM/BuizyEz/BuiMyEz/BuizyEM', 'BuiMyanai/Buizyanai/BuiMyane/Buizyane/BuiMyanE/BuizyanE', 'BuiMyeM/Buizyez/BuiMyez/BuizyeM/BuiMyaiM/Buizyaiz/BuiMyaiz/BuizyaiM/BuiMyEM/BuizyEz/BuiMyEz/BuizyEM', 'BuiMyanai/Buizyanai/BuiMyane/Buizyane/BuiMyanE/BuizyanE'),\n",
    "    ('PotoiyA', 'Potoiye/Potoiyai/PotoiE', 'Potoiye/Potoiyai/PotoiE', 'Potoiye/Potoiyai/PotoiE', 'Potoiyane/Potyanai/PotanE')\n",
    "]\n",
    "\n",
    "# Prepare the output structure\n",
    "categories = []\n",
    "word_roots = []\n",
    "word_forms = []\n",
    "\n",
    "# Process the input data\n",
    "for entry in data:\n",
    "    word_root, form1, form2, form3, form4 = entry\n",
    "    categories.append(\"Noun_f_rednt_e\")  # New category for this dataset\n",
    "    word_roots.append(word_root)\n",
    "    word_forms.append([form1, form2, form3, form4])\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Category': categories,\n",
    "    'Word Root': word_roots,\n",
    "    'Word Form 1': [forms[0] for forms in word_forms],\n",
    "    'Word Form 2': [forms[1] for forms in word_forms],\n",
    "    'Word Form 3': [forms[2] for forms in word_forms],\n",
    "    'Word Form 4': [forms[3] for forms in word_forms],\n",
    "})\n",
    "\n",
    "# Save to Excel\n",
    "df.to_excel('word_data_noun_f_rednt_e.xlsx', index=False)\n",
    "\n",
    "print(\"Data has been saved to 'word_data_noun_f_rednt_e.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5f6730a-6ba7-4e00-b0ea-2708bb3625f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to 'word_data_noun_f_rednt_e1.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Input data\n",
    "data = [\n",
    "    ('ladZakiyA', 'ladZakiyo/ladZakiyO/ladZakiyau', 'ladZakiyano/ladZakiyanO/ladZakiyanau/ladZakiano/ladZakianO/ladZakianau', 'ladZakiyo/ladZakiyO/ladZakiyau', 'ladZakiyano/ladZakiyanO/ladZakiyanau/ladZakiano/ladZakianO/ladZakianau'),\n",
    "    ('maiyA', 'maiyo/maiyO/maiyau/maio/maiau/maiO', 'maiyano/maiyanO/maiyanau/maiano/maianO/maianau', 'maiyo/maiyO/maiyau/maio/maiau/maiO', 'maiyano/maiyanO/maiyanau/maiano/maianO/maianau'),\n",
    "    ('rawiyA', 'rawiyo/rawiyO/rawiyau/rawio/rawiau/rawiO', 'rawiyo/rawiyO/rawiyau/rawio/rawiau/rawiO', 'rawiyo/rawiyO/rawiyau/rawio/rawiau/rawiO', 'rawiyano/rawiyanO/rawiyanau/rawiano/rawianO/rawianau'),\n",
    "    ('OrawiyA', 'Orawiyo/OrawiyO/Orawiyau/Orawio/OrawiO/Orawiau', 'Orawiyano/OrawiyanO/Orawiyanau/Orawiano/OrawianO/Orawianau', 'Orawiyo/OrawiyO/Orawiyau/Orawio/OrawiO/Orawiau', 'Orawiyano/OrawiyanO/Orawiyanau/Orawiano/OrawianO/Orawianau'),\n",
    "    ('BasavA', 'Basavo/BasavO/Basavau', 'Basavo/BasavO/Basavau', 'Basavo/BasavO/Basavau', 'Basavano/BasavanO/Basavanau'),\n",
    "    ('lauvA', 'lauvo/lauvau/lauvO/lauo/lauau/lauO', 'lauvano/lauano/lauvanau/lauanau/lauvanO/lauanO/', 'lauvo/lauvau/lauvO/lauo/lauau/lauO', 'lauvano/lauano/lauvanau/lauanau/lauvanO/lauanO/'),\n",
    "    ('gudZiyavA', 'gudZiyavo/gudZiavo/gudZiyavau/gudZiavau/gudZiyavO/gudZiavO', 'gudZiyavo/gudZiavo/gudZiyavau/gudZiavau/gudZiyavO/gudZiavO', 'gudZiyavo/gudZiavo/gudZiyavau/gudZiavau/gudZiyavO/gudZiavO', 'gudZiyavano/gudZiyavanO/gudZiyavanau/gudZiavano/gudZiavanau/gudZiavanO'),\n",
    "    ('sakwiyA', 'sakwiyo/sakwiyO/sakwiyau', 'sakwiyo/sakwiyO/sakwiyau', 'sakwiyo/sakwiyO/sakwiyau', 'sakwiyano/sakwiyanO/sakwiyanau'),\n",
    "    ('bahuvA', 'bahuvo/bahuvO/bahuvau', 'bahuvo/bahuvO/bahuvau', 'bahuvo/bahuvO/bahuvau', 'bahuvano/bahuvanO/bahuvanau'),\n",
    "    ('qwuvA', 'qwuvo/qwuvO/qwuvau', 'qwuvo/qwuvO/qwuvau', 'qwuvo/qwuvO/qwuvau', 'qwuvano/qwuvanO/qwuvanau'),\n",
    "    ('BoravA', 'Boravo/BoravO/Boravau', 'Boravo/BoravO/Boravau', 'Boravo/BoravO/Boravau', 'Boravano/BoravanO/Boravanau'),\n",
    "    ('BarasaiMyAM', 'BarasaiMyoM/BarasaiMyOM/BarasaiMyauM/BarasaiMyoz/BarasaiMyOz/BarasaiMyauz/BarasaizyoM/BarasaizyOM/BarasaizyauM/Barasaizyoz/BarasaizyOz/Barasaizyauz', 'BarasaiMyanoM/BarasaiMyanauM/BarasaiMyanOM/BarasaiMyanoz/BarasaiMyanauz/BarasaiMyanOz/Barasaizyanoz/Barasaizyanauz/BarasaizyanOz/BarasaizyanoM/BarasaizyanauM/BarasaizyanOM', 'BarasaiMyoM/BarasaiMyOM/BarasaiMyauM/BarasaiMyoz/BarasaiMyOz/BarasaiMyauz/BarasaizyoM/BarasaizyOM/BarasaizyauM/Barasaizyoz/BarasaizyOz/Barasaizyauz', 'BarasaiMyanoM/BarasaiMyanauM/BarasaiMyanOM/BarasaiMyanoz/BarasaiMyanauz/BarasaiMyanOz/Barasaizyanoz/Barasaizyanauz/BarasaizyanOz/BarasaizyanoM/BarasaizyanauM/BarasaizyanOM'),\n",
    "    ('BOMvAM', 'BOMvoM/BOzvoz/BOMvauM/BOzvauz/BOMvOM/BOzvOz/BOMvoz/BOzvoM/BOMvauz/BOzvaM/BOMvOz/BOzvOM', 'BOMvano/Bozvano/BOMvanau/Bozvanau/BOMvanO/BozvanO', 'BOMvoM/BOzvoz/BOMvauM/BOzvauz/BOMvOM/BOzvOz/BOMvoz/BOzvoM/BOMvauz/BOzvaM/BOMvOz/BOzvOM', 'BOMvano/Bozvano/BOMvanau/Bozvanau/BOMvanO/BozvanO'),\n",
    "    ('PotoM', 'PotoMiyoM/Potoziyoz/PotoMiyoz/PotoziyoM/PotoMiyOM/PotoziyOz/PotoMiyOz/PotoziyOM/PotoMiyauM/Potoziyauz/PotoMiyauz/PotoziyauM', 'PotoMiyoM/Potoziyoz/PotoMiyoz/PotoziyoM/PotoMiyOM/PotoziyOz/PotoMiyOz/PotoziyOM/PotoMiyauM/Potoziyauz/PotoMiyauz/PotoziyauM', 'PotoMiyoM/Potoziyoz/PotoMiyoz/PotoziyoM/PotoMiyOM/PotoziyOz/PotoMiyOz/PotoziyOM/PotoMiyauM/Potoziyauz/PotoMiyauz/PotoziyauM', 'PotoMiyano/Potoziyano/PotoMiyanO/PotoziyanO/PotoMiyanau/Potoziyanau'),\n",
    "    ('BuiMyAM', 'BuiMyoM/Buizyoz/BuiMyoz/BuizyoM/BuiMyauM/Buizyauz/BuiMyauz/BuizyauM/BuiMyOM/BuizyOz/BuiMyOz/BuizyOM', 'BuiMyanau/Buizyanau/BuiMyanO/BuizyanO/BuiMyano/Buizyano', 'BuiMyoM/Buizyoz/BuiMyoz/BuizyoM/BuiMyauM/Buizyauz/BuiMyauz/BuizyauM/BuiMyOM/BuizyOz/BuiMyOz/BuizyOM', 'BuiMyanau/Buizyanau/BuiMyanO/BuizyanO/BuiMyano/Buizyano'),\n",
    "    ('PotoiyA', 'Potoiyo/Potoiyau/PotoiO', 'Potoiyo/Potoiyau/PotoiO', 'Potoiyo/Potoiyau/PotoiO', 'Potoiyano/Potyanau/PotanO')\n",
    "]\n",
    "# Prepare the output structure\n",
    "categories = []\n",
    "word_roots = []\n",
    "word_forms = []\n",
    "\n",
    "# Process the input data\n",
    "for entry in data:\n",
    "    word_root, form1, form2, form3, form4 = entry\n",
    "    categories.append(\"Noun_f_rednt_e1\")  # New category for this dataset\n",
    "    word_roots.append(word_root)\n",
    "    word_forms.append([form1, form2, form3, form4])\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Category': categories,\n",
    "    'Word Root': word_roots,\n",
    "    'Word Form 1': [forms[0] for forms in word_forms],\n",
    "    'Word Form 2': [forms[1] for forms in word_forms],\n",
    "    'Word Form 3': [forms[2] for forms in word_forms],\n",
    "    'Word Form 4': [forms[3] for forms in word_forms],\n",
    "})\n",
    "\n",
    "# Save to Excel\n",
    "df.to_excel('word_data_noun_f_rednt_e1.xlsx', index=False)\n",
    "\n",
    "print(\"Data has been saved to 'word_data_noun_f_rednt_e1.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b23c49e-a705-4847-95cd-42ad7febce24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to 'Advrb_e_dataset.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Input data for Advrb_e\n",
    "data = [\n",
    "    ('aba', 'abbai/abai/aBI/abahi/abahI'),\n",
    "    ('kala', 'kalai/kAlhai/kalE/kAlhE'),\n",
    "    ('Aja', 'Ajai/AjE/Ajahi/Ajuve'),\n",
    "    ('parasoM', 'parasavaiz/parasaveM/parasavahi/parasave/parasoMveM/parasoveM/parasoMyeM/parasoMeM/parasozvez/parasovez/parasozyeM/parasoMez'),\n",
    "    ('bihAna', 'bihAnai/bihAne/bihAnE/bihanai'),\n",
    "    ('sabere', 'sabarahi/sabarahI/saberahi/saberahI/saberai'),\n",
    "    ('subaha', 'subahai/subahiyai/subahe'),\n",
    "    ('XIre', 'XirahI/Xirahi/XirehI/XIrehi/XirahIM/XirahiM'),\n",
    "    ('hamesA', 'hamesahi/hamesahI/hamesai'),\n",
    "    ('nIce', 'nIcahi/nIcahI/nIcahai/nicehI/nicehi/nIcahE'),\n",
    "    ('aso', 'asavai/asave/asavahi/asave/asove/asoye/asoe'),\n",
    "    ('begahUz', 'begahuzveM/begahuMveM/begahuzvez/begahuMvez/begahuzyeM/begahuMyeM/begahuzyez/begahuMyez'),\n",
    "    ('anaxeKe', 'anaxeKalai/anaxeKale'),\n",
    "    ('ahewu', 'ahewue/ahewuve/ahewuye'),\n",
    "    ('beAbarU', 'beAbarue/beAbaruve/beAbaruye'),\n",
    "    ('awi', 'awiye/awie/awiyai/awiai'),\n",
    "    ('kaBI', 'kaBiye/kaBie/kaBiyai'),\n",
    "    ('abahIz', 'abahizye/abahiMye/abahize/abahiMe/abahiMyai/abahizyai'),\n",
    "    ('jahAz', 'jahez/jaheM/jahEz/jahEM')\n",
    "]\n",
    "\n",
    "# Prepare the output structure\n",
    "# Prepare the output structure\n",
    "categories = []\n",
    "word_roots = []\n",
    "word_forms1 = []\n",
    "word_forms2 = []\n",
    "word_forms3 = []\n",
    "word_forms4 = []\n",
    "\n",
    "# Process the input data\n",
    "for entry in data:\n",
    "    word_root, forms = entry\n",
    "    forms_list = forms.split('/')\n",
    "    categories.append(\"Advrb_e\")  # New category for this dataset\n",
    "    word_roots.append(word_root)\n",
    "    \n",
    "    # Ensure we handle up to 4 forms, pad with empty strings if fewer forms are present\n",
    "    for i in range(4):\n",
    "        if i < len(forms_list):\n",
    "            if i == 0:\n",
    "                word_forms1.append(forms_list[i])\n",
    "            elif i == 1:\n",
    "                word_forms2.append(forms_list[i])\n",
    "            elif i == 2:\n",
    "                word_forms3.append(forms_list[i])\n",
    "            elif i == 3:\n",
    "                word_forms4.append(forms_list[i])\n",
    "        else:\n",
    "            # Pad missing forms with empty strings\n",
    "            if i == 0:\n",
    "                word_forms1.append('')\n",
    "            elif i == 1:\n",
    "                word_forms2.append('')\n",
    "            elif i == 2:\n",
    "                word_forms3.append('')\n",
    "            elif i == 3:\n",
    "                word_forms4.append('')\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Category': categories,\n",
    "    'Word Root': word_roots,\n",
    "    'Word Form 1': word_forms1,\n",
    "    'Word Form 2': word_forms2,\n",
    "    'Word Form 3': word_forms3,\n",
    "    'Word Form 4': word_forms4\n",
    "})\n",
    "\n",
    "# Save to an Excel file\n",
    "df.to_excel('Advrb_e_dataset3.xlsx', index=False)\n",
    "\n",
    "print(\"Data has been saved to 'Advrb_e_dataset.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61265e19-b2d1-46ca-bf50-588a602195fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from docx import Document\n",
    "\n",
    "# Load the Word document\n",
    "doc_path = 'B_M_M_Word-generation-ver-1.9.0.docx'\n",
    "document = Document(doc_path)\n",
    "\n",
    "# Initialize lists to store data from the \"Category\" and \"SL inputs\"\n",
    "categories = []\n",
    "sl_inputs = []\n",
    "\n",
    "# Iterate through the tables in the document\n",
    "for table in document.tables:\n",
    "    for row in table.rows:\n",
    "        # Assuming \"Category\" is in the first column (index 0) \n",
    "        # and \"SL inputs\" is in the second column (index 1)\n",
    "        categories.append(row.cells[0].text)\n",
    "        sl_inputs.append(row.cells[1].text)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "data = {\n",
    "    'Category': categories,\n",
    "    'SL Inputs': sl_inputs\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "excel_file_path = 'extracted_categories_sl_inputs.xlsx'\n",
    "df.to_excel(excel_file_path, index=False)\n",
    "\n",
    "print(f\"Data from the 'Category' and 'SL inputs' has been extracted and saved to '{excel_file_path}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f4a1516-97b8-42cc-b051-2d3641700884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from rows 3 and 4 has been extracted and saved to 'extracted_categories_sl_inputs_specific_rows.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from docx import Document\n",
    "\n",
    "# Load the Word document\n",
    "doc_path = 'B_M_M_Word-generation-ver-1.9.0.docx'\n",
    "document = Document(doc_path)\n",
    "\n",
    "# Initialize lists to store data from the \"Category\" and \"SL inputs\"\n",
    "categories = []\n",
    "sl_inputs = []\n",
    "\n",
    "# Iterate through the tables in the document\n",
    "for table in document.tables:\n",
    "    for i, row in enumerate(table.rows):\n",
    "        # Check if the row index is 3 or 4 (keeping in mind that row indices are zero-based)\n",
    "        if i in [2, 3]:  # Adjust indices based on your requirement (3rd and 4th rows)\n",
    "            # Assuming \"Category\" is in the first column (index 0) \n",
    "            # and \"SL inputs\" is in the second column (index 1)\n",
    "            categories.append(row.cells[0].text)\n",
    "            sl_inputs.append(row.cells[1].text)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "data = {\n",
    "    'Category': categories,\n",
    "    'SL Inputs': sl_inputs\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "excel_file_path = 'extracted_categories_sl_inputs_specific_rows.xlsx'\n",
    "df.to_excel(excel_file_path, index=False)\n",
    "\n",
    "print(f\"Data from rows 3 and 4 has been extracted and saved to '{excel_file_path}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df60f93a-7c85-45d3-82b9-f7d9c9017982",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
